{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Description : Reads the NOBEL data from the excel and updates in the database tables \n",
    "STAGING_NOBLE, STAGING_FILES_READ, JOBS_SCHEDULE. The log of the script is found in \n",
    "./logs and the data is loaded in ./data.\n",
    "\n",
    "Author : Krishnendu Das\n",
    "\n",
    "Date : 21-01-2019\n",
    "\n",
    "Version : 1.0\n",
    "\n",
    "Html : TBD\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import cx_Oracle  as ora\n",
    "\n",
    "status_flag = 'Started'\n",
    "desc = \"PARSE_NOBLE_DATA_JOB\"\n",
    "\n",
    "\n",
    "#oracle connection details\n",
    "conn = ora.connect('system/1234@localhost:1521/xe')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# insert into the job table\n",
    "queryjob = 'insert into JOBS_SCHEDULE (id, DESCRIPTIONS,START_DATE,STATUS) values (JOB_SEQ.NEXTVAL,:bdesc,sysdate,:bstatus_flag)'\n",
    "cursor.execute(queryjob, bdesc=desc,bstatus_flag =status_flag)\n",
    "cursor.execute('select JOB_SEQ.currval i from dual')\n",
    "run_id = int(re.sub('[^0-9]+', '', str(cursor.fetchall())))\n",
    "conn.commit()\n",
    "               \n",
    "try:\n",
    "\n",
    "    #logging script\n",
    "    log_path = \"C:/Users/Jennifer/Documents/GitHub/BI_Reporting/logs/\" \n",
    "    now = datetime.datetime.now()\n",
    "    date = now.strftime(\"%d_%m_%Y\")\n",
    "    logfile = 'log_'+date+'.txt' \n",
    "    logs = os.listdir(log_path)\n",
    "    \n",
    "    # create the log file\n",
    "    if logfile not in logs:\n",
    "        logging = open(log_path+logfile, 'w')\n",
    "    else:\n",
    "        logging = open(log_path+logfile, 'a')\n",
    "\n",
    "    logging.write(\"  \\n\")\n",
    "    logging.write(\"############################################\\n\")\n",
    "    logging.write(\"################### START ##################\\n\")\n",
    "    logging.write(\"############################################\\n\")\n",
    "\n",
    "    path = \"C:/Users/Jennifer/Documents/GitHub/BI_Reporting/data/\" \n",
    "    files = os.listdir(path)\n",
    " \n",
    "    for f in files:\n",
    "        print(f,file=logging)\n",
    "\n",
    "        # query1\n",
    "        querystring1 = \"alter session set nls_date_format = 'mm/dd/yyyy'\"\n",
    "        cursor.execute(querystring1)\n",
    "        logging.write(\"Query 1 Executed\\n\")\n",
    "\n",
    "        # query2\n",
    "        querystring2 = \"select * from STAGING_FILES_READ\"\n",
    "        cursor.execute(querystring2)\n",
    "        logging.write(\"Query 2 Executed\\n\")\n",
    "        files_arx = re.sub('[^0-9a-zA-Z._,]+', '', str(cursor.fetchall()))[:-1].split(',,')\n",
    "\n",
    "        if f.replace(' ','') not in files_arx:\n",
    "            # read the csv files\n",
    "            nobel_data = pd.read_csv(path+f, names =(\"Agent Hours\",\n",
    "                                                     \"col1\",\"col2\",\n",
    "                                                     \"col3\", \"col4\",\n",
    "                                                     \"col5\",\"col6\",\n",
    "                                                     \"col7\",\"col8\",\n",
    "                                                     \"col9\",\"col10\"))\n",
    "\n",
    "            # get the index where Agent Name is present\n",
    "            header_dupes = nobel_data[nobel_data['Agent Hours'] == 'Agent Name'].index.tolist()\n",
    "\n",
    "            # data cleansing\n",
    "            nobel_data = nobel_data.iloc[header_dupes[0]:].dropna()\n",
    "            nobel_data = nobel_data.reset_index(drop=True)\n",
    "            nobel_data.columns = list(nobel_data.iloc[0])\n",
    "            nobel_data = nobel_data.drop(index=nobel_data[nobel_data['Agent Name'] == 'Agent Name'].index.tolist())\n",
    "            nobel_data = nobel_data.reset_index(drop=True)\n",
    "\n",
    "            # query3\n",
    "            querystring3 = \"insert into STAGING_NOBLE (AGENT_NAME, \\\n",
    "                                                      CODE, \\\n",
    "                                                      CONTACT_DATE, \\\n",
    "                                                      LOGON_TIME, \\\n",
    "                                                      LOGOFF_TIME, \\\n",
    "                                                      CONNECTED, \\\n",
    "                                                      WAITING, \\\n",
    "                                                      PAUSED, \\\n",
    "                                                      DEASSIGN, \\\n",
    "                                                      ACW, \\\n",
    "                                                      TOTAL, \\\n",
    "                                                      FILE_NAME) \\\n",
    "                                        VALUES ('%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s','%s')\"\n",
    "\n",
    "            # loop thourhg dataframe \n",
    "            for i in range(len(nobel_data)):\n",
    "                \n",
    "                # update the job table\n",
    "                status_flag = \"Running\"\n",
    "                queryjob = \"UPDATE JOBS_SCHEDULE SET status = :bstatus_flag WHERE id = :brun_id\"\n",
    "                cursor.execute(queryjob, bstatus_flag=status_flag, brun_id=run_id )\n",
    "                conn.commit()\n",
    "\n",
    "                # define the bind variables for data entry\n",
    "                cursor.execute(querystring3 % (nobel_data['Agent Name'][i],\n",
    "                                               nobel_data['Code'][i],\n",
    "                                               nobel_data['Contact Date'][i],\n",
    "                                               nobel_data['Logon Time'][i],\n",
    "                                               nobel_data['Logoff Time'][i],\n",
    "                                               nobel_data['Connect'][i],\n",
    "                                               nobel_data['Waiting'][i],\n",
    "                                               nobel_data['Paused'][i],\n",
    "                                               nobel_data['Deassign'][i],\n",
    "                                               nobel_data['ACW'][i],\n",
    "                                               nobel_data['Total'][i],\n",
    "                                               f)\n",
    "                              )\n",
    "\n",
    "            logging.write(\"Query 3 Executed\\n\") \n",
    "\n",
    "            # query4\n",
    "            querystring4 = \"insert into STAGING_FILES_READ values ('%s')\"\n",
    "            cursor.execute(querystring4 % (f))\n",
    "            logging.write(\"Query 4 Executed\\n\")\n",
    "\n",
    "            #commit after all the data is entered\n",
    "            conn.commit()\n",
    "            logging.write(\"Total\"+str(len(nobel_data))+'rows were inserted to the table STAGING_NOBLE\\n')\n",
    "            logging.write(\"             \\n\") \n",
    "\n",
    "        else:\n",
    "\n",
    "            logging.write('File:'+str(f)+'previously uploaded\\n')\n",
    "\n",
    "    logging.write(\"############################################\\n\")\n",
    "    logging.write(\"################### END ##################\\n\")\n",
    "    logging.write(\"############################################\\n\")\n",
    "\n",
    "    success_flag = True \n",
    "    logging.write(\"SQL connection closed\")\n",
    "    \n",
    "    status_flag = 'Finished'\n",
    "    \n",
    "except Exception as e: \n",
    "    \n",
    "    status_flag = 'Error'\n",
    "    logging.write(\"\\nERROR : ++++++++++++++++++++++++++++++++++++\\n\")\n",
    "    logging.write (str(e)+'\\n')\n",
    "    logging.write(\"++++++++++++++++++++++++++++++++++++++++++\\n\\n\")\n",
    "\n",
    "#update the job table\n",
    "queryjob = \"UPDATE JOBS_SCHEDULE SET status = :bstatus_flag, end_date = sysdate WHERE id = :brun_id \"\n",
    "cursor.execute(queryjob, bstatus_flag=status_flag, brun_id = run_id )\n",
    "conn.commit()\n",
    "    \n",
    "cursor.close()\n",
    "conn.close()\n",
    "logging.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
